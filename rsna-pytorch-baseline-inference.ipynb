{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rimzakhama/rsna-pytorch-baseline-inference?scriptVersionId=143880360\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from IPython.display import display_html\ndef restartkernel() :\n    display_html(\"\",raw=True)\nrestartkernel()\n\n\n# Install timm package from local directory\n!pip install '/kaggle/input/timm-pack/timm_package/timm-0.6.12-py3-none-any.whl'\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-07T10:55:25.30907Z","iopub.execute_input":"2023-03-07T10:55:25.309561Z","iopub.status.idle":"2023-03-07T10:55:55.30869Z","shell.execute_reply.started":"2023-03-07T10:55:25.309523Z","shell.execute_reply":"2023-03-07T10:55:55.30741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The medical images provided are in (two types of) Dicom format, and in order to read these \n# we will need to install and import the required dependent libraries:\n\n'''\n## If Online : install required packages for dcm processing \n!pip install -qU pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg pydicom python-gdcm dicomsdl\n\n#import all the required dicom packages\nimport gdcm\nimport pydicom\nimport pylibjpeg\nimport dicomsdl\n'''\n\n!pip install pylibjpeg --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read\n!pip install pylibjpeg-openjpeg --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read\n!pip install pylibjpeg-libjpeg --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read\n!pip install pydicom --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read\n!pip install python-gdcm --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read\n!pip install dicomsdl --no-index --find-links=file:///kaggle/input/read-dicom-set/dicom_read","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:55:55.311455Z","iopub.execute_input":"2023-03-07T10:55:55.311854Z","iopub.status.idle":"2023-03-07T10:56:52.070572Z","shell.execute_reply.started":"2023-03-07T10:55:55.311814Z","shell.execute_reply":"2023-03-07T10:56:52.069388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\n\nimport os\n\n#import pydicom as dicom\nimport pydicom\nimport cv2\n\nimport timm\nimport torch.optim as optim\nfrom sklearn import model_selection\nfrom sklearn.metrics import f1_score\n\nfrom tqdm.autonotebook import tqdm\n\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.072782Z","iopub.execute_input":"2023-03-07T10:56:52.073192Z","iopub.status.idle":"2023-03-07T10:56:52.245082Z","shell.execute_reply.started":"2023-03-07T10:56:52.073153Z","shell.execute_reply":"2023-03-07T10:56:52.244133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config :\n    BATCH_SIZE = 2\n    MODEL_PATH = '/kaggle/input/efficientb4-model/model.bin'\n    NUM_CLASSES = 1","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.248498Z","iopub.execute_input":"2023-03-07T10:56:52.249138Z","iopub.status.idle":"2023-03-07T10:56:52.255092Z","shell.execute_reply.started":"2023-03-07T10:56:52.249079Z","shell.execute_reply":"2023-03-07T10:56:52.254161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Dataset:\n    def __init__(self, df, transform=None):\n        self.df = df.copy()\n        self.transform = transform\n     \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        patient_id = self.df.loc[idx, 'patient_id']\n        image_id = self.df.loc[idx, 'image_id']\n        prediction_id = self.df.loc[idx, 'prediction_id']\n        \n        # Get and preprocess images\n        # This path should be changed\n        #png_path = '/kaggle/input/rsna-png-images-same-format-as-original/output/rsna_pngs/train_images'\n        png_path = '/kaggle/working/output/test_images' # test images path\n        # Image path\n        image_png_path =  os.path.join(png_path, patient_id.astype(str), image_id.astype(str)+'.png')\n\n        image = mpimg.imread(image_png_path)\n        \n        image = cv2.resize(image, (512,512))\n        \n        # Apply transformers on images\n        if self.transform:\n            image = self.transform(image)\n            \n     \n        \n        # Convert to tensors\n        image = torch.tensor(image, dtype=torch.long)\n        \n        \n        \n        #{ 'image' : torch.tensor(image, dtype=torch.long),\n         #        'prediction_id' : prediction_id\n          #         }\n        \n        return image, prediction_id","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.256682Z","iopub.execute_input":"2023-03-07T10:56:52.257049Z","iopub.status.idle":"2023-03-07T10:56:52.268071Z","shell.execute_reply.started":"2023-03-07T10:56:52.257007Z","shell.execute_reply":"2023-03-07T10:56:52.267208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BreastCancerModel(nn.Module):\n    def __init__(self, Config):\n        super().__init__()\n        self.efficientnet = timm.create_model('efficientnet_b4', pretrained=False,\n                                             in_chans=1)\n        in_features = self.efficientnet.classifier.in_features\n        self.efficientnet.classifier = nn.Linear(in_features, Config.NUM_CLASSES)   \n        \n    def forward(self, image):\n        output = self.efficientnet(image)\n        \n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.269583Z","iopub.execute_input":"2023-03-07T10:56:52.270154Z","iopub.status.idle":"2023-03-07T10:56:52.282763Z","shell.execute_reply.started":"2023-03-07T10:56:52.270118Z","shell.execute_reply":"2023-03-07T10:56:52.281844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Probabilistic F1 score'''\ndef pfbeta(labels, predictions, beta):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.284294Z","iopub.execute_input":"2023-03-07T10:56:52.284647Z","iopub.status.idle":"2023-03-07T10:56:52.293062Z","shell.execute_reply.started":"2023-03-07T10:56:52.284614Z","shell.execute_reply":"2023-03-07T10:56:52.292109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess test images (convert to png format)\n\ntest_dcm_images_path = '/kaggle/input/rsna-breast-cancer-detection/test_images'\npatient = '10008'\nsize = 512\n\npatient_input_path = test_dcm_images_path + '/' + patient\n\n# Convert test images to png\n#output_path =  '/kaggle/working/output/rsna_pngs/test_images'\noutput_path =  '/kaggle/working/output/test_images'\n\n# Create directory if it does not exists\nif not os.path.isdir(output_path+'/'+patient):\n    os.makedirs(output_path+'/'+patient)\n\nfor image in os.listdir(patient_input_path):\n    image_input_path = patient_input_path + '/'+ image\n    dicom_image = pydicom.dcmread(image_input_path)\n    \n    image_array = dicom_image.pixel_array\n    scaled_img = (np.maximum(image_array,0) / image_array.max()) * 255.0\n    if dicom_image.PhotometricInterpretation == \"MONOCHROME1\":\n        scaled_img = 1 - scaled_img\n    img = scaled_img.astype(np.uint8)\n    resized_image = cv2.resize(img, (size, size))\n    \n    \n    cv2.imwrite(output_path + '/' + patient + '/' + image.replace('dcm', 'png'),resized_image)\n\n    # Plot png image\n    img = mpimg.imread(output_path + '/' + patient + '/' + image.replace('dcm', 'png'))\n    imgplot = plt.imshow(img)\n    plt.show()\n\n    \n#The inference will be applied on dcm or pngs images??\n\n# This code should be, first, applied on test images, then submitted\n# to be tested on kaggle test dataset.\n\n# But the question is : what is the format of the test images in submission?","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:52.294316Z","iopub.execute_input":"2023-03-07T10:56:52.294652Z","iopub.status.idle":"2023-03-07T10:56:55.645319Z","shell.execute_reply.started":"2023-03-07T10:56:52.294619Z","shell.execute_reply":"2023-03-07T10:56:55.644382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfx = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = BreastCancerModel(Config=Config)\n\nmodel.to(device)\n\nmodel.load_state_dict(torch.load(Config.MODEL_PATH))\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.ToTensor()\n    ])\n\ndataset = Dataset(dfx, transform=transform)\ndata_loader = torch.utils.data.DataLoader(dataset, batch_size= Config.BATCH_SIZE,\n                                             num_workers=2)\n\nsample = pd.DataFrame(columns = ['prediction_id', 'cancer'])\nwith torch.no_grad():\n    for batch_idx, (images, prediction_id) in enumerate(data_loader):\n        images = images.to(device, dtype=torch.float) \n        outputs = model(images).squeeze()\n        predictions = outputs.sigmoid().cpu().numpy()\n        \n        new_dataframe = pd.DataFrame({'prediction_id' : prediction_id , 'cancer' : predictions })\n        sample = pd.concat([sample, new_dataframe])\n        \n# Put the results in the format of submission file\nsample = sample.groupby('prediction_id')['cancer'].mean().reset_index()\nTHRES = 0.84\nsample['cancer'] = (sample.cancer > THRES).astype(float)\n\n# Save sample DataFrame as csv\nsample.to_csv('submission.csv', index=False)\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:56:55.646695Z","iopub.execute_input":"2023-03-07T10:56:55.647777Z","iopub.status.idle":"2023-03-07T10:57:08.088872Z","shell.execute_reply.started":"2023-03-07T10:56:55.647738Z","shell.execute_reply":"2023-03-07T10:57:08.087738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nHow can we improve our results:\n- Create folds and different models.\n- improve the model architecture\n- change the model\n- train the pretrained model??\n- change the transform, do augmentations on images\n- increase number of epochs\n- Use features fro csv file to improve the accuracy\n- change the optimizer and its parameters\n\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-03-07T10:57:08.092792Z","iopub.execute_input":"2023-03-07T10:57:08.093134Z","iopub.status.idle":"2023-03-07T10:57:08.102337Z","shell.execute_reply.started":"2023-03-07T10:57:08.093079Z","shell.execute_reply":"2023-03-07T10:57:08.101148Z"},"trusted":true},"execution_count":null,"outputs":[]}]}