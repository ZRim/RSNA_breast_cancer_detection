{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm -q","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:11.853760Z","iopub.execute_input":"2023-05-30T11:41:11.854724Z","iopub.status.idle":"2023-05-30T11:41:23.386956Z","shell.execute_reply.started":"2023-05-30T11:41:11.854677Z","shell.execute_reply":"2023-05-30T11:41:23.385752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\n\n# image manipulation\nimport cv2\nimport PIL\nfrom PIL import Image\n\n# visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# helpers\nfrom tqdm import tqdm\nimport time\nimport copy\nimport gc\nfrom enum import Enum\n\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve\n\nimport timm\n\n\n# for cnn\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, AdamW, SGD\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, random_split, TensorDataset, Dataset, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\nfrom torchvision import models\nfrom torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryAccuracy, BinaryROC, BinaryAUROC\nfrom torchvision import transforms\nimport albumentations as A","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.389617Z","iopub.execute_input":"2023-05-30T11:41:23.390046Z","iopub.status.idle":"2023-05-30T11:41:23.399189Z","shell.execute_reply.started":"2023-05-30T11:41:23.390007Z","shell.execute_reply":"2023-05-30T11:41:23.398237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    print('> SEEDING DONE')\n    \nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.400857Z","iopub.execute_input":"2023-05-30T11:41:23.401535Z","iopub.status.idle":"2023-05-30T11:41:23.415420Z","shell.execute_reply.started":"2023-05-30T11:41:23.401504Z","shell.execute_reply":"2023-05-30T11:41:23.414429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RSNAMamographyDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.df = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n\n    def __getitem__(self, ind):\n        \n        img_path = f\"{self.img_dir}/{self.df.iloc[ind].patient_id}_{self.df.iloc[ind].image_id}.png\"\n        img = Image.open(img_path).convert('RGB')\n        \n        label = self.df.iloc[ind].cancer\n        # there is no need to normalize data, it has already been normalized\n        if self.transform:\n            img = self.transform(img).to(torch.float32) \n        else:\n            default_transform = transforms.Compose([transforms.ToTensor()])\n            img = default_transform(img).to(torch.float32)\n            \n        #sample = {\"image\" : img, \"label\": label}\n        \n        label = label.to(torch.long)\n        \n        return img, label","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.418517Z","iopub.execute_input":"2023-05-30T11:41:23.419258Z","iopub.status.idle":"2023-05-30T11:41:23.428255Z","shell.execute_reply.started":"2023-05-30T11:41:23.419226Z","shell.execute_reply":"2023-05-30T11:41:23.427281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Dataset:\n    def __init__(self, df, transform):\n        self.df = df.copy()\n        self.transform = transform\n     \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        patient_id = self.df.loc[idx, 'patient_id']\n        image_id = self.df.loc[idx, 'image_id']\n        # Target\n        target = self.df.loc[idx, 'cancer'] \n        \n        # Get and preprocess images\n        #dcm_path = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n        #image = dicom.dcmread(image_path)\n        \n        #png_path = '/kaggle/input/rsna-png-images-same-format-as-original/output/rsna_pngs/train_images'\n        #png_path = '/kaggle/input/png-cutted-images/output/png_cutted_images' # my work\n        png_path = '/kaggle/input/preprocessed-images/train_images' # préprocessed images by vladimir\n        \n        # Image path\n        #image_dcm_path =  os.path.join(png_path, patient_id.astype(str), image_id.astype(str)+'.dcm')\n        image_png_path =  os.path.join(png_path, patient_id.astype(str), image_id.astype(str)+'.png')\n\n        # convert image to RGB\n        image = Image.open(image_png_path).convert('RGB')\n        \n        # Check if image is RGB \n        #print('image shape = ', np.array(image).shape)\n        \n        image = image.resize((1024,912)) # 512,512 ??\n        \n        # Apply transformers on images\n        if (target == 1) and self.transform:\n            image = self.transform(image).to(torch.float32)\n        else :\n            default_transform = transforms.Compose([transforms.ToTensor()])\n            image = default_transform(image).to(torch.float32)\n            #image = image.to(torch.float32)\n                    \n        # Convert to tensors\n        #image = torch.tensor(image, dtype=torch.float32)\n        \n        target = torch.tensor(target, dtype=torch.long)\n        \n        return image, target","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.430000Z","iopub.execute_input":"2023-05-30T11:41:23.430657Z","iopub.status.idle":"2023-05-30T11:41:23.446428Z","shell.execute_reply.started":"2023-05-30T11:41:23.430625Z","shell.execute_reply":"2023-05-30T11:41:23.445417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resnet and Efficientnet\nclass Models(nn.Module):\n    def __init__(self):\n        super(Models, self).__init__()\n        #self.network = models.resnet18(pretrained=True)\n        #n_features = self.network.fc.out_features\n        \n        # Resnet\n        self.resnet = timm.create_model('resnet18', pretrained=True, in_chans=3)\n        n_features_resnet = self.resnet.fc.out_features\n        \n        self.classifier_layer_resnet = nn.Sequential(\n            nn.Linear(n_features_resnet , 256),\n            nn.Dropout(0.8), #0.3\n            nn.Linear(256 , 1) #NUM_CLASSES = 1\n        )\n        \n        # Efficientnet\n        self.efficientnet = timm.create_model('efficientnet_b4', pretrained=True, in_chans=3)\n        in_features_efficientnet = self.efficientnet.classifier.in_features\n        \n        self.classifier_layer_efficientnet = nn.Sequential(\n            nn.Linear(in_features_efficientnet , 256),\n            nn.Dropout(0.3),\n            nn.Linear(256 , 1)\n        )\n    \n    #if resenet\n    #def forward(self, xb):        \n     #   xb = self.resnet(xb)\n     #   xb = self.classifier_layer_resnet(xb)\n     #   return xb\n    \n    #if efficientnet\n    def forward(self, xb):        \n        xb = self.efficientnet(xb)\n        xb = self.classifier_layer_efficientnet(xb)\n        return xb\n    \n        #return torch.sigmoid(xb)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.448672Z","iopub.execute_input":"2023-05-30T11:41:23.449557Z","iopub.status.idle":"2023-05-30T11:41:23.461544Z","shell.execute_reply.started":"2023-05-30T11:41:23.449523Z","shell.execute_reply":"2023-05-30T11:41:23.460562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        #self.network = models.resnet18(pretrained=True)\n        #n_features = self.network.fc.out_features\n        \n        self.network = timm.create_model('resnet18', pretrained=True, in_chans=3)\n        n_features = self.network.fc.out_features\n        \n        # add additional layer that maps 2048 extracted features from resnet to 1 feature \n        #determining the class\n        self.classifier_layer = nn.Sequential(\n            nn.Linear(n_features , 256),\n            nn.Dropout(0.8),\n            nn.Linear(256 , 1)\n        )\n    \n    def forward(self, xb):        \n        xb = self.network(xb)\n        xb = self.classifier_layer(xb)\n        return torch.sigmoid(xb)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.463113Z","iopub.execute_input":"2023-05-30T11:41:23.463824Z","iopub.status.idle":"2023-05-30T11:41:23.476004Z","shell.execute_reply.started":"2023-05-30T11:41:23.463778Z","shell.execute_reply":"2023-05-30T11:41:23.475034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Only resnet\nclass CNN_RESNET(nn.Module):\n    def __init__(self):\n        super(CNN_RESNET, self).__init__()\n        #self.network = models.resnet18(pretrained=True)\n        #n_features = self.network.fc.out_features\n        \n        self.resnet = timm.create_model('resnet18', pretrained=True, in_chans=3) #resnet18\n        n_features = self.resnet.fc.out_features\n        \n        # add additional layer that maps 2048 extracted features from resnet to 1 feature \n        #determining the class\n        self.classifier_layer = nn.Sequential(\n            nn.Linear(n_features , 256),\n            nn.Dropout(0.8), #0.3\n            nn.Linear(256 , 1)\n        )\n    \n    def forward(self, xb):        \n        xb = self.resnet(xb)\n        xb = self.classifier_layer(xb)\n        return xb\n        #return torch.sigmoid(xb)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.477638Z","iopub.execute_input":"2023-05-30T11:41:23.478414Z","iopub.status.idle":"2023-05-30T11:41:23.490283Z","shell.execute_reply.started":"2023-05-30T11:41:23.478381Z","shell.execute_reply":"2023-05-30T11:41:23.489430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n        super(GeM, self).__init__()\n        if p_trainable:\n            self.p = Parameter(torch.ones(1) * p)\n        else:\n            self.p = p\n        self.eps = eps\n\n    def forward(self, x):\n        ret = gem(x, p=self.p, eps=self.eps)\n        return ret\n\n    def __repr__(self):\n        return (\n            self.__class__.__name__\n            + \"(\"\n            + \"p=\"\n            + \"{:.4f}\".format(self.p.data.tolist()[0])\n            + \", \"\n            + \"eps=\"\n            + str(self.eps)\n            + \")\"\n        )\n    \nclass MammoModel(nn.Module):\n    def __init__(self, name, *, pretrained=False, in_chans=3, p=3, p_trainable=False, eps=1e-6):\n        super().__init__()\n        model = timm.create_model(name, pretrained=pretrained, in_chans=in_chans)\n        clsf = model.default_cfg['classifier']\n        n_features = model._modules[clsf].in_features\n        model._modules[clsf] = nn.Identity()\n        \n        self.fc = nn.Linear(n_features, 1) # cancer\n        self.model = model\n\n        self.pool = nn.Sequential(\n            GeM(p=p, eps=eps, p_trainable=p_trainable),\n            nn.Flatten())\n    \n    def forward(self, x):\n        x = self.model(x)\n        #x = self.model.forward_features(x)\n        #x = self.pool(x)\n        logits = self.fc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.491885Z","iopub.execute_input":"2023-05-30T11:41:23.492661Z","iopub.status.idle":"2023-05-30T11:41:23.506142Z","shell.execute_reply.started":"2023-05-30T11:41:23.492629Z","shell.execute_reply":"2023-05-30T11:41:23.505210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Model (we need to improve our model''' \nclass BreastCancerModel(nn.Module):\n    def __init__(self, Config):\n        super().__init__()\n        # efficientnet\n        self.efficientnet = timm.create_model('efficientnet_b4', pretrained=True,\n                                             in_chans=3)\n        in_features = self.efficientnet.classifier.in_features\n        self.efficientnet.classifier = nn.Linear(in_features, Config.NUM_CLASSES)  \n        \n        \n        # Resnet\n        self.resnet = timm.create_model('resnet50', pretrained=True, in_chans=3)\n        self.resnet.fc = nn.Linear(2048, Config.NUM_CLASSES)\n    \n        \n    def forward(self, image):\n        output = self.efficientnet(image)\n        #output = self.resnet(image)\n    \n        return output\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.511061Z","iopub.execute_input":"2023-05-30T11:41:23.511336Z","iopub.status.idle":"2023-05-30T11:41:23.520986Z","shell.execute_reply.started":"2023-05-30T11:41:23.511314Z","shell.execute_reply":"2023-05-30T11:41:23.520054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def BCELoss_class_weighted(weights):\n    \"\"\"\n    weights[0] is weight for class 0 (negative class)\n    weights[1] is weight for class 1 (positive class)\n    \"\"\"\n    def loss(y_pred, target):\n        y_pred = torch.clamp(y_pred,min=1e-7,max=1-1e-7) # for numerical stability\n        bce = - weights[1] * target * torch.log(y_pred) - (1 - target) * weights[0] * torch.log(1 - y_pred)\n        return torch.mean(bce)\n\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.522259Z","iopub.execute_input":"2023-05-30T11:41:23.523065Z","iopub.status.idle":"2023-05-30T11:41:23.534703Z","shell.execute_reply.started":"2023-05-30T11:41:23.523035Z","shell.execute_reply":"2023-05-30T11:41:23.533829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create class for earlystopping\nclass EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_loss = np.inf\n\n    def early_stop(self, loss):\n        if loss <= self.min_loss:\n            self.min_loss = loss\n            self.counter = 0\n        elif loss > (self.min_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.536168Z","iopub.execute_input":"2023-05-30T11:41:23.537129Z","iopub.status.idle":"2023-05-30T11:41:23.545073Z","shell.execute_reply.started":"2023-05-30T11:41:23.537096Z","shell.execute_reply":"2023-05-30T11:41:23.544173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_optimal_threshold(fpr, tpr, thresholds): # based on ROC curve\n    J = tpr - fpr\n    index = np.argmax(J)\n    OptThreshold = thresholds[index]\n    return OptThreshold\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.547595Z","iopub.execute_input":"2023-05-30T11:41:23.548286Z","iopub.status.idle":"2023-05-30T11:41:23.555639Z","shell.execute_reply.started":"2023-05-30T11:41:23.548263Z","shell.execute_reply":"2023-05-30T11:41:23.554787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Training function'''\ndef train(data_loader, model, optimizer, device, scheduler=None):\n    # Set model in training mode\n    model.train()\n    \n    # Metrics\n    metricf1 = BinaryF1Score()\n    precision = BinaryPrecision()\n    recall = BinaryRecall()\n    accuracy = BinaryAccuracy()\n    roc = BinaryROC()\n    auc = BinaryAUROC()\n    \n    train_metrics = {'loss' : [], 'acc' : [], 'f1': [], 'precision': [], 'recall': [], 'auc': []}\n    \n    # Initial threshold\n    threshold = 0.5\n        \n\n    # DataLoader\n    tk0 = tqdm(data_loader, total=len(data_loader))\n    \n    running_loss = 0\n    correct = 0\n    total = 0\n    all_outputs = torch.Tensor([])\n    all_labels = torch.Tensor([]) # needed to calculate auc score ??\n   \n    for batch_idx, data in enumerate(tk0):\n        images = data[0]\n        targets = data[1]\n        \n        targets = torch.unsqueeze(targets, 1)\n        \n        images = images.to(device).float() \n        targets = targets.to(device).float() # long\n        \n        #print('targets shape = ', targets.shape)\n        \n        optimizer.zero_grad()\n        \n        with torch.set_grad_enabled(True):\n        \n            outputs = model(images)#.squeeze()\n            #print('outputs shape = ', outputs.shape)\n\n            loss = criterion(outputs, targets)\n            \n            loss.backward()\n            optimizer.step()\n            \n            # all outputs\n            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))\n            \n            # all labels\n            all_labels = torch.cat((all_labels, targets.to('cpu')))\n            \n\n            # Correct classifications\n            probs = outputs#.sigmoid() # in this case we don't need sigmoid because we have it in the \n            # model class !!\n            predicted_vals = probs > threshold\n            correct += torch.sum(predicted_vals == targets.data)\n\n\n            # Total classifications\n            total += targets.size(0)\n            \n        #auc score\n        #auc_score = roc_auc_score(all_labels.detach().numpy(), all_outputs .detach().numpy())\n        \n        # running loss    \n        running_loss += loss.item()\n\n        # collect any unused memmory\n        #gc.collect()\n        #torch.cuda.empty_cache()\n\n    #Accuracy\n    accu = correct/total\n    \n    # Average training loss (epoch loss)\n    train_loss = running_loss / len(data_loader)\n    \n    #auc score\n    auc_score = roc_auc_score(all_labels.detach().numpy(), all_outputs.detach().numpy())\n    \n    \n    # ROC\n    print('all_labels type', all_labels.dtype)\n    fpr, tpr, thresholds = roc(all_outputs, all_labels.long())\n    \n    \n    # Find optimal threshold\n    OptThreshold = find_optimal_threshold(fpr, tpr, thresholds)\n    \n    \n    print(f'New threshold is {OptThreshold}')\n    \n    # Calculate metrics using optimized threshold\n    # f1 score\n    f1_measure = metricf1(all_outputs > OptThreshold, all_labels)\n    \n    '''\n    # need to be runned ??\n    # find True positive rate and False postive rate for ROC curve\n    fpr, tpr, thresholds = roc(all_outputs, all_labels)\n    epoch_auc = auc(all_outputs, all_labels)\n\n    # Find new threshold\n    # we need a function here to find the optimal threshold\n\n    # Calculate metrics using the optimized threshold\n    f1_measure = metricf1(all_outputs > threshold, all_labels)\n    epoch_acc = accuracy(all_outputs > threshold, all_labels)\n    epoch_precision = precision(all_outputs > threshold, all_labels)\n    epoch_recall = recall(all_outputs > threshold, all_labels)\n\n    # Save the metrics\n    scheduler.step()\n    train_metrics['loss'].append(train_loss)\n    train_metrics['acc'].append(epoch_acc)\n    train_metrics['f1'].append(f1_measure)\n    train_metrics['precision'].append(epoch_precision)\n    train_metrics['recall'].append(epoch_recall)\n    train_metrics['auc'].append(epoch_auc)\n    \n    tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'], \n                                                train_metrics['acc'],  train_metrics['f1'],\n                                                train_metrics['precision'], \n                                                train_metrics['recall'], \n                                                train_metrics['auc']\n    \n    #tr_loss, tr_acc, tr_f1, tr_prec, tr_rec, tr_auc = train_metrics['loss'][-1], \n    #                                            train_metrics['acc'][-1],  train_metrics['f1'][-1],\n    #                                            train_metrics['precision'][-1], \n    #                                            train_metrics['recall'][-1], \n    #                                            train_metrics['auc'][-1]\n                                                \n    print(f'Train Loss: {tr_loss:.4f}, Train Acc: {tr_acc:.4f}, \n          Train f1: {tr_f1:.4f}, Train Precision: {tr_prec:.4f}, \n          Train Recall: {tr_rec:.4f}, Train AUC: {tr_auc:.4f}')\n\n    '''\n   \n    print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))\n    print('auc_score : %.3f'%(auc_score))\n    print('f1_measure : %.3f'%(f1_measure))\n  \n    \n   \n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.557388Z","iopub.execute_input":"2023-05-30T11:41:23.558020Z","iopub.status.idle":"2023-05-30T11:41:23.575651Z","shell.execute_reply.started":"2023-05-30T11:41:23.557990Z","shell.execute_reply":"2023-05-30T11:41:23.574822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Evaluation function'''\n\ndef evaluation(data_loader, model, device):\n    model.eval()\n    \n    # Metrics\n    metricf1 = BinaryF1Score()\n    precision = BinaryPrecision()\n    recall = BinaryRecall()\n    accuracy = BinaryAccuracy()\n    roc = BinaryROC()\n    auc = BinaryAUROC()\n    \n    \n    predictions = []\n    tar = []\n    running_loss = 0\n    correct = 0\n    total = 0\n    \n    threshold = 0.5\n    \n    all_outputs = torch.Tensor([])\n    all_labels = torch.Tensor([]) # needed to calculate auc score ??\n    \n    for batch_idx, data in enumerate(data_loader):\n            images = data[0]\n            targets = data[1]\n            \n            #targets = torch.unsqueeze(targets.to(torch.float), 1) #float32\n            targets = torch.unsqueeze(targets, 1)\n        \n            images = images.to(device, dtype=torch.float) \n            targets = targets.to(device, dtype=torch.float) # long ??\n       \n            with torch.no_grad():\n                outputs = model(images)#.squeeze()\n                loss = criterion(outputs, targets) \n                \n            # all outputs\n            all_outputs = torch.cat((all_outputs, outputs.to('cpu')))\n            \n            # all labels\n            all_labels = torch.cat((all_labels, targets.to('cpu')))    \n            \n            running_loss += loss.item()\n            \n            # Correct classifications (for accuracy calculation)\n            probs = outputs#.sigmoid()\n            predicted_vals = probs > threshold\n            correct += torch.sum(predicted_vals == targets.data)\n            # Total classifications\n            total += targets.size(0)\n            \n    \n            # Predictions\n            predictions.append(predicted_vals.cpu().numpy())\n            \n            # Targets\n            tar.append(targets.cpu().numpy())\n            \n            # collect any unused memmory\n            #gc.collect()\n            #torch.cuda.empty_cache()\n     \n    # Loss \n    eval_loss = running_loss / len(data_loader)\n    # Accuracy\n    eval_accu = correct/total\n    print('Eval Loss: %.3f | Accuracy: %.3f'%(eval_loss,eval_accu))\n    \n    #auc score\n    eval_auc_score = roc_auc_score(all_labels.detach().numpy(), all_outputs .detach().numpy())\n    \n    # ROC\n    print('type of labels', all_labels.dtype)\n    fpr, tpr, thresholds = roc(all_outputs, all_labels.long())\n    \n    # Find optimal threshold\n    OptThreshold = find_optimal_threshold(fpr, tpr, thresholds)\n    \n    # Calculate metrics using optimized threshold\n    # f1 score\n    eval_f1_measure = metricf1(all_outputs > OptThreshold, all_labels)\n    \n    \n    # Predictions\n    predictions = np.concatenate(predictions) # this line convert the list \n      # of lists into a 1d array.\n        \n    # Targets    \n    tar = np.concatenate(tar)\n    \n    print('Eval Loss: %.3f | Eval Accuracy: %.3f'%(eval_loss,eval_accu))\n    print('Eval auc_score : %.3f'%(eval_auc_score))\n    print('Eval_f1_measure : %.3f'%(eval_f1_measure))\n\n    return predictions, tar, OptThreshold     \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.578636Z","iopub.execute_input":"2023-05-30T11:41:23.578982Z","iopub.status.idle":"2023-05-30T11:41:23.594359Z","shell.execute_reply.started":"2023-05-30T11:41:23.578957Z","shell.execute_reply":"2023-05-30T11:41:23.593497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n    since = time.time()\n    \n    train_metrics = {'loss' : []}\n    val_metrics = {'loss' : []}\n    \n    print('Starting training...')\n    print('-' * 20)\n    for epoch in range(num_epochs):\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            \n            if phase == 'train':\n                model.train()  # Set model to training model\n            else:\n                model.eval()   # Set model to evaluate model\n\n            running_loss = 0.0\n            \n            # Iterate over data.\n            print(f'{phase} for epoch {epoch + 1}')\n            for inputs, labels in tqdm(dataloaders[phase]):\n                print('labels shape before unsqueeze : ', labels.shape)\n                labels = torch.unsqueeze(labels.to(torch.long), 1) #float32\n                print('labels shape after unsqueeze : ', labels.shape)\n            \n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    print('outputs shape = ', outputs.shape)\n                    preds = (outputs > 0.5).double()\n                                       \n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n\n                # statistics\n                running_loss += loss.item()\n\n                # collect any unused memmory\n                gc.collect()\n                torch.cuda.empty_cache()\n            \n            # statistics\n            epoch_loss = running_loss / len(dataloaders[phase])\n            \n            # save all of the statistics for latter analysis\n            if phase == 'train':\n                scheduler.step()\n                train_metrics['loss'].append(epoch_loss)\n                \n            else:\n                val_metrics['loss'].append(epoch_loss)\n                \n                    \n        # cant be formated in string\n        tr_loss = train_metrics['loss'][-1]\n        val_loss = val_metrics['loss'][-1]\n        \n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print(f'Train Loss: {tr_loss:.4f}')\n        print(f'Valitadion Loss: {val_loss:.4f}')\n        \n        if earlystoper.early_stop(val_loss):\n            break\n        \n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    \n    return train_metrics, val_metrics","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.595732Z","iopub.execute_input":"2023-05-30T11:41:23.596295Z","iopub.status.idle":"2023-05-30T11:41:23.610514Z","shell.execute_reply.started":"2023-05-30T11:41:23.596265Z","shell.execute_reply":"2023-05-30T11:41:23.609647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Probabilistic F1 score'''\ndef pfbeta(labels, predictions, beta):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n    \n    \n    for idx in range(len(labels)):  \n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.611826Z","iopub.execute_input":"2023-05-30T11:41:23.612359Z","iopub.status.idle":"2023-05-30T11:41:23.624035Z","shell.execute_reply.started":"2023-05-30T11:41:23.612329Z","shell.execute_reply":"2023-05-30T11:41:23.623441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\nimgs_dir = '/kaggle/input/rsnamamorgaphybreastcancerrecognition512x512'\n\n'''\naugmentator = transforms.Compose([\n    # input for augmentator is always PIL image\n    # transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomVerticalFlip(0.5),\n    transforms.RandomRotation(5),\n    transforms.ToTensor(), # return it as a tensor and transforms it to [0, 1]\n])\n'''\ntransform = transforms.Compose([\n    transforms.ToTensor()])\n\n'''\naugmentator = transforms.Compose([\n    # input for augmentator is always PIL image\n    # transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomAffine(degrees=(0, 180), scale=(0.8, 1.2)),\n    transforms.ElasticTransform(),\n    transforms.ToTensor(), # return it as a tensor and transforms it to [0, 1]\n])\n\n'''\n\naugmentator = transforms.Compose([\n    # input for augmentator is always PIL image\n    # transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(0.5),\n    transforms.RandomVerticalFlip(0.5),\n    #transforms.RandomPerspective(),\n    #transforms.RandomRotation((0, 90)),\n    #transforms.RandomAutocontrast(),\n    #transforms.RandomAffine(degrees=(0, 180), scale=(0.8, 1.2)),\n    #transforms.ElasticTransform(),\n    transforms.ToTensor(), # return it as a tensor and transforms it to [0, 1]\n])\n\n\n#dataset = RSNAMamographyDataset(train_csv, imgs_dir, augmentator)\ndfx = pd.read_csv(train_csv)\ndataset = Dataset(dfx, transform=augmentator)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.625167Z","iopub.execute_input":"2023-05-30T11:41:23.625711Z","iopub.status.idle":"2023-05-30T11:41:23.757017Z","shell.execute_reply.started":"2023-05-30T11:41:23.625681Z","shell.execute_reply":"2023-05-30T11:41:23.756117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pct = 0.1\nval_size = int(val_pct * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.758426Z","iopub.execute_input":"2023-05-30T11:41:23.758768Z","iopub.status.idle":"2023-05-30T11:41:23.781756Z","shell.execute_reply.started":"2023-05-30T11:41:23.758736Z","shell.execute_reply":"2023-05-30T11:41:23.780963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' WeightedRandomSampler for imbalanced data'''\n\n'''\ndftrain = pd.read_csv(train_csv)\n\n\nprint(\"Class counting...\")\nlabels = dftrain['cancer'].values\nclass_sample_count = np.array([len(np.where(labels == l)[0]) for l in np.unique(labels)])\n\nprint(class_sample_count)\n\nprint(\"Adding weights to each training sample...\")\n# class_sample_count[1] *= 5 # ??\nclass_weights = 1. / class_sample_count\nsample_weights = []\nfor _, label in tqdm(train_dataset):\n    sample_weights.append(class_weights[label])\n    \n    \n# the trouble with this aproach is that it now has to load all images one by one and label them\n# but it saves RAM memory in training process    \n    \nsample_weights = np.array(sample_weights)\nsample_weights = torch.from_numpy(sample_weights)\n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.783333Z","iopub.execute_input":"2023-05-30T11:41:23.783726Z","iopub.status.idle":"2023-05-30T11:41:23.791872Z","shell.execute_reply.started":"2023-05-30T11:41:23.783695Z","shell.execute_reply":"2023-05-30T11:41:23.790841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nweighted_random_sampler = WeightedRandomSampler(sample_weights, len(sample_weights),\n                                               replacement=True)\nweighted_random_sampler\n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.793643Z","iopub.execute_input":"2023-05-30T11:41:23.794420Z","iopub.status.idle":"2023-05-30T11:41:23.806867Z","shell.execute_reply.started":"2023-05-30T11:41:23.794315Z","shell.execute_reply":"2023-05-30T11:41:23.805835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size =  32 #32\n\n# Applying sampler just to train dataset, not for validation, since the validation dataset \n# should be an imitation of real Dataset\n\n#train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = False, num_workers = 2, \n#                              pin_memory = True, sampler = weighted_random_sampler) # using our sampler\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True, num_workers = 2, \n                              pin_memory = True) # random sampler\n\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False, pin_memory = True)\n# If you use shuffle = True the DataLoader will initialize a RandomSampler for you, \n# otherwise it’ll use SequentialSampler.","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.808070Z","iopub.execute_input":"2023-05-30T11:41:23.808519Z","iopub.status.idle":"2023-05-30T11:41:23.817070Z","shell.execute_reply.started":"2023-05-30T11:41:23.808489Z","shell.execute_reply":"2023-05-30T11:41:23.816134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {'train' : train_dataloader, 'val' : val_dataloader}\ndataset_sizes = {'train': train_size, 'val' : val_size}","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.818255Z","iopub.execute_input":"2023-05-30T11:41:23.818948Z","iopub.status.idle":"2023-05-30T11:41:23.826586Z","shell.execute_reply.started":"2023-05-30T11:41:23.818916Z","shell.execute_reply":"2023-05-30T11:41:23.825718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' Weighted loss for imbalanced data '''\n\n# Number of samples for each class\nsamples_classes = dfx['cancer'].value_counts()\nprint(samples_classes)\n\n#pos_weight = 53548/1158\npos_weight = torch.tensor([46]).cuda()\n\n#criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:23.828286Z","iopub.execute_input":"2023-05-30T11:41:23.828979Z","iopub.status.idle":"2023-05-30T11:41:29.472452Z","shell.execute_reply.started":"2023-05-30T11:41:23.828948Z","shell.execute_reply":"2023-05-30T11:41:29.471427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        #self.network = models.resnet18(pretrained=True)\n        #n_features = self.network.fc.out_features\n        \n        self.network = timm.create_model('resnet18', pretrained=True, in_chans=3)\n        n_features = self.network.fc.out_features\n        \n        # add additional layer that maps 2048 extracted features from resnet to 1 feature \n        #determining the class\n        self.classifier_layer = nn.Sequential(\n            nn.Linear(n_features , 256),\n            nn.Dropout(0.3),\n            nn.Linear(256 , 1)\n        )\n    \n    def forward(self, xb):        \n        xb = self.network(xb)\n        xb = self.classifier_layer(xb)\n        return xb","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:29.474940Z","iopub.execute_input":"2023-05-30T11:41:29.475238Z","iopub.status.idle":"2023-05-30T11:41:29.484025Z","shell.execute_reply.started":"2023-05-30T11:41:29.475213Z","shell.execute_reply":"2023-05-30T11:41:29.483027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define the model\n#model = MammoModel('efficientnet_v2_s', pretrained=True) #efficientnet_b5\nmodel = CNN()\n#model = BreastCancerModel(Config=Config)\nmodel.to(device)\n\n# Define the criterion (loss)\n#w_pos = 3\n#w_neg = 1\n#criterion = BCELoss_class_weighted(weights = [w_neg, w_pos])\n\n# or\ncriterion = nn.BCEWithLogitsLoss()\n\n# Define the optimizer\noptimizer = AdamW(model.parameters(), lr=2.56e-05)\n\n# Define the metric\nmetric = BinaryF1Score().to(device)\n\n\nearlystoper = EarlyStopper(patience = 3)\n\n# Scheduler\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\n\n# Model path\n#model_path = f\"model_{fold}.bin\"\nmodel_path = \"model.bin\"\n    \n# Run\nbest_score = 0\nfor epoch in range(5):\n    train(train_dataloader, model, optimizer, device, scheduler)\n    predictions, targets, OptThreshold = evaluation(val_dataloader, model, device)\n\n    print('epoch = ', epoch)\n\n    F1_score = pfbeta(targets, predictions, beta=1)\n\n    if F1_score > best_score:\n        best_score = F1_score\n        \n        PATH = \"model.pt\"\n        checkpoint = torch.save({\n            'model_state_dict': model.state_dict(),\n            'threshold' : OptThreshold\n            }, PATH)\n        \n    print('f1_score = ', best_score)     \n\nprint('best_score_ever = ', best_score) \n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:29.485544Z","iopub.execute_input":"2023-05-30T11:41:29.486607Z","iopub.status.idle":"2023-05-30T11:41:35.153523Z","shell.execute_reply.started":"2023-05-30T11:41:29.486575Z","shell.execute_reply":"2023-05-30T11:41:35.150488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In this version, we used :\n# - only augmentations,\n# - preproccessed images from vladimir, notebook : https://www.kaggle.com/code/rimzakhama/cut-off-empty-space-from-images/notebook\n# ","metadata":{"execution":{"iopub.status.busy":"2023-05-30T11:41:35.155363Z","iopub.status.idle":"2023-05-30T11:41:35.156193Z","shell.execute_reply.started":"2023-05-30T11:41:35.155908Z","shell.execute_reply":"2023-05-30T11:41:35.155934Z"},"trusted":true},"execution_count":null,"outputs":[]}]}